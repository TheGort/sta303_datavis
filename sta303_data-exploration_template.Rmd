---
output:
  pdf_document:
    latex_engine: xelatex
  html_document:
    df_print: paged
urlcolor: blue
header-includes:    
  - \usepackage{lastpage}
  - \usepackage{fancyhdr}
  - \pagestyle{fancy}
  - \fancyhead[CO, CE]{David Pham, 1005349053}
  - \fancyfoot[CO, CE]{\thepage \ of \pageref{LastPage}}
---
```{r setup, message = FALSE, echo=FALSE, warning=FALSE}
# Students: You probably shouldn't change any of the code in this chunk.

# These are the packages you will need for this activity
packages_needed <- c("tidyverse", "googledrive", "readxl", "janitor", 
                     "lubridate", "opendatatoronto", "ggthemes")

package.check <- lapply(
  packages_needed,
  FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
      install.packages(x, dependencies = TRUE)
    }
  }
)

# Credit: package.check based on a helpful post from Vikram Baliga https://vbaliga.github.io/verify-that-r-packages-are-installed-and-loaded/

# Load tidyverse
library(tidyverse)
library(readxl)
library(janitor)
library(opendatatoronto)
library(ggthemes)

# Set so that long lines in R will be wrapped:
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80), echo = FALSE)
```


```{r getdata, eval = FALSE, echo=FALSE}
# Students: You probably shouldn't change any of the code in this chunk BUT...

# This chunk loads the most recent data from Toronto City and the data from OpenToronto.

# You have to RUN this chunk by hand to update the data as 
#   eval is set to FALSE to limit unnecessary requsts on the site.

###################################################
# Step one: Get the COVID data from Toronto City. #
###################################################

googledrive::drive_deauth()

url1 <- "https://drive.google.com/file/d/11KF1DuN5tntugNc10ogQDzFnW05ruzLH/view"
googledrive::drive_download(url1, path="data/CityofToronto_COVID-19_Daily_Public_Reporting.xlsx", overwrite = TRUE)

url2 <- "https://drive.google.com/file/d/1jzH64LvFQ-UsDibXO0MOtvjbL2CvnV3N/view"
googledrive::drive_download(url2, path = "data/CityofToronto_COVID-19_NeighbourhoodData.xlsx", overwrite = TRUE)

# this removes the url object that we don't need anymore
rm(url1, url2)

#####################################################################
# Step two: Get the data neighbourhood data from Open Data Toronto. #
#####################################################################

nbhoods_shape_raw <- list_package_resources("neighbourhoods") %>% 
  get_resource()

saveRDS(nbhoods_shape_raw, "data/neighbourhood_shapefile.Rds")

nbhood_profile <- search_packages("Neighbourhood Profile") %>%
  list_package_resources() %>% 
  filter(name == "neighbourhood-profiles-2016-csv") %>% 
  get_resource()

saveRDS(nbhood_profile, "data/neighbourhood_profile.Rds")
```


```{r load_data, echo=FALSE}
######################################################
# Step three: Load the COVID data from Toronto City. #
######################################################

# Saving the name of the file as an object and then using the object name in the
# following code is a helpful practice. Why? If we change the name of the file 
# being used, we'll only have to change it in one place. This helps us avoid 
# 'human error'.

daily_data <- "data/CityofToronto_COVID-19_Daily_Public_Reporting.xlsx"

# Cases reported by date
reported_raw <- read_excel(daily_data, sheet = 5) %>% 
  clean_names()

# Cases by outbreak type
outbreak_raw <- read_excel(daily_data, sheet = 3) %>% 
  clean_names()

# When was this data updated?
date_daily <- read_excel(daily_data, sheet = 1) %>% 
  clean_names()

# By neighbourhood
neighbourood_data <- "data/CityofToronto_COVID-19_NeighbourhoodData.xlsx"

# Cases reported by date
nbhood_raw <- read_excel(neighbourood_data, sheet = 2) %>% 
  clean_names()

# Date the neighbourhood data was last updated
date_nbhood <- read_excel(neighbourood_data, sheet = 1) %>% 
  clean_names()

#don't need these anymore
rm(daily_data, neighbourood_data)

#############################################################
# Step four: Load the neighbourhood data from Toronto City. #
#############################################################

# Get neighbourhood profile data
nbhood_profile <- readRDS("data/neighbourhood_profile.Rds")

# Get shape data for mapping 
nbhoods_shape_raw <- readRDS("data/neighbourhood_shapefile.Rds") %>% 
  sf::st_as_sf() ## Makes sure shape info is in the most up to date format

```

Code last run `r Sys.Date()`.  
Daily: `r date_daily[1,1]`.   
Neighbourhood: `r date_nbhood[1,1]`. 

# Task 1: Daily cases
## Data wrangling

```{r cases_dw, warning=FALSE, echo=TRUE}
reported <- reported_raw %>%
  mutate_if(is.numeric, replace_na, replace=0)

# reformat dates
reported$reported_date <- as.Date(reported$reported_date, "%Y-%m-%d")

# capitalize column names
colnames(reported)[2] <- "Recovered"
colnames(reported)[3] <- "Active"
colnames(reported)[4] <- "Deceased"

# move columns around
reported <- reported[c("reported_date", "Active", "Recovered", "Deceased")]

# need to make a new column called "Case Type", as data is not tidy
reported_long <- reported %>%
  pivot_longer(-reported_date, names_to = "case_type") %>%
  uncount(value)

# create factor levels (sort of cheating)
fac_levels <- c("Active", "Recovered", "Deceased")

# verify that reported_date is indeed in date format
# glimpse(reported)
```

\newpage
## Data visualization

```{r cases_vis, echo=TRUE, warning = FALSE}
reported_long %>%
  count(case_type, reported_date) %>%
  ggplot(aes(x = reported_date, y = n, fill = factor(case_type, levels = fac_levels))) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(title = "Cases reported by day in Toronto, Canada",
       subtitle = "Confirmed and probable cases",
       x = "Date",
       y = "Case count",
       caption = str_c("Created by: David Pham for STA303/1002, U of T\n",
                       "Source: Ontario Ministry of Health, Integrated Public Health Information System and CORES\n", 
                       date_daily[1,1])) +
  scale_x_date(limits = c(date("2020-01-01"), Sys.Date()), date_labels = "%d %b %y") +
  theme(legend.title = element_blank(), legend.position = c(0.15, 0.8)) +
  scale_y_continuous(limits = c(0, 2000), breaks = seq(0, 2000, by = 500)) +
  scale_fill_manual(values = c("#003F5C", "#86BCB6", "#B9CA5D"))

```

\newpage
# Task 2: Outbreak type
## Data wrangling


```{r outbreak_dw, echo=TRUE, warning = FALSE}
# create total_cases variable and fix wording for outbreak type
outbreak <- outbreak_raw %>%
  mutate(outbreak_or_sporadic = str_replace(outbreak_or_sporadic, "OB A", "Outbreak a")) %>%
  group_by(episode_week) %>%
  mutate(total_cases = sum(cases))

# reformat dates
outbreak$episode_week <- as.Date(outbreak$episode_week, "%Y-%m-%d")

# verify that episode_week is indeed in date format
# glimpse(outbreak)

# create factors (sort of cheating)
fac_levels <- c("Sporadic", "Outbreak associated")
```

\newpage
## Data visualization

```{r outbreak_vis, echo=TRUE, warning=FALSE}
outbreak %>%
  ggplot(aes(x = episode_week, y = cases, fill = factor(outbreak_or_sporadic, levels = fac_levels))) +
  geom_bar(stat = "identity", width = 7) +
  theme_minimal() +
  labs(title = "Cases by outbreak type and week in Toronto, Canada",
       subtitle = "Confirmed and probable cases",
       x = "Date",
       y = "Case count",
       caption = str_c("Created by: David Pham for STA303/1002, U of T\n", 
                       "Source: Ontario Ministry of Health, Integrated Public Health Information System and CORES\n", 
                       date_daily[1,1])) +
  scale_x_date(labels = scales::date_format("%d %b %y"), 
               limits = c(date("2020-01-01"), Sys.Date()+7)) +
  theme(legend.title = element_blank(), legend.position = c(0.15, 0.8)) +
  scale_y_continuous(limits = c(0, max(outbreak$total_cases)), 
                     breaks = seq(0, max(outbreak$total_cases), by = 2000)) +
  scale_fill_manual(values = c("#86BCB6", "#B9CA5D"))
```

\newpage
# Task 3: Neighbourhoods
## Data wrangling: part 1

```{r nbhood_dw_1, echo = TRUE}
# filter for the correct row (we'll use LICO-AT)
income <- nbhood_profile %>%
  filter(nbhood_profile$Category == "Income", nbhood_profile$Topic == "Low income in 2015",
         nbhood_profile$Characteristic == "  18 to 64 years (%)", nbhood_profile$'_id' == 1143)

# delete unnecessary variables
income <- select(income, c(-'_id', -Category, -Topic, -Characteristic, -"Data Source"))

# make data tidy so that we only have neighbourhood names and % of low income 18 to 64 year olds
income <- income %>%
  pivot_longer(cols = everything(), names_to = "neighbourhood_name", values_to = "Percentage")

# change value types in percentages column to doubles
income$Percentage <- parse_number(income$Percentage)

# glimpse(income)
```

## Data wrangling: part 2

```{r nbhood_dw_2, echo = TRUE}
# make neighbourhood_name variable, mutating AREA_NAME
nbhoods_all <- nbhoods_shape_raw %>%
  mutate(neighbourhood_name = str_replace_all(string = nbhoods_shape_raw$AREA_NAME,
                                              pattern = "\\s\\(\\d+\\)$",
                                              replacement = ""))

# after a bit of observing, it appears that three neighbourhoods have been spelt incorrectly in nbhoods_all...
# we'll edit the city names in 'neighbourhood_name' so that we don't NA values when merging datasets.
nbhoods_all$neighbourhood_name[127] <- "Cabbagetown-South St. James Town"
nbhoods_all$neighbourhood_name[76] <- "Weston-Pelham Park"
nbhoods_all$neighbourhood_name[54] <- "North St. James Town"

# left join nbhood_raw and income datasets to nbhoods_all by 'neighbourhood_name'
nbhoods_all <- left_join(nbhoods_all, nbhood_raw, by = "neighbourhood_name") %>%
  left_join(., income, by = "neighbourhood_name")

# rename rate_per_100_000_people to rate_per_100000
colnames(nbhoods_all)[21] <- "rate_per_100000"

```

\newpage

## Data wrangling: part 3

```{r nbhood_dw_3, echo = TRUE}
# create med_inc, med_rate and nbhood_type variables
nbhoods_final <- nbhoods_all %>%
  mutate(med_inc = median(Percentage, na.rm = TRUE), med_rate = median(rate_per_100000, na.rm = TRUE),
         nbhood_type = ifelse(Percentage >= med_inc & rate_per_100000 >= med_rate,
                              "Higher low income rate, higher case rate",
                              ifelse(Percentage >= med_inc & rate_per_100000 < med_rate, 
                                     "Higher low income rate, lower case rate",
                                     ifelse(Percentage < med_inc & rate_per_100000 >= med_rate,
                                            "Lower low income rate, higher case rate",
                                            ifelse(Percentage < med_inc & rate_per_100000 < med_rate,
                                                   "Lower low income rate, lower case rate", NA)))))
```

\newpage
## Data visualization

```{r neighbourhood_graphs_1, fig.height=4, echo = TRUE}
ggplot(data = nbhoods_final) +
  geom_sf(aes(fill = Percentage)) +
  theme_map() +
  labs(title = "Percentage of 18 to 64 year olds living in a low income family (2015)",
       subtitle = "Neighbourhoods of Toronto, Canada",
       caption = str_c("Created by: David Pham for STA303/1002, U of T\n", 
                       "Source: Census Profile 98-316-X2016001 via OpenData Toronto\n", 
                       date_daily[1,1])) +
  theme(legend.position = 'right') +
  scale_fill_gradient(name = "% low income", low = "darkgreen", high = "lightgrey")
```

\newpage

```{r neighbourhood_graphs_2, fig.height=4, echo = TRUE}
ggplot(data = nbhoods_final) +
  geom_sf(aes(fill = rate_per_100000)) +
  theme_map() +
  labs(title = "COVID-19 cases per 100,000, by neighbourhood in Toronto, Canada",
       caption = str_c("Created by: David Pham for STA303/1002, U of T\n", 
                       "Source: Ontario Ministry of Health, Integrated Public Health Information System and CORES\n", 
                       date_daily[1,1])) +
  theme(legend.position = 'right') +
  scale_fill_gradient(name = "Cases per 100,000 people", low = "white", high = "darkorange")
```

\newpage

```{r neighbourhood_graphs_3, fig.height=4, echo = TRUE}
ggplot(data = nbhoods_final) +
  geom_sf(aes(fill = nbhood_type)) +
  theme_map() +
  labs(title = "COVIDâˆ’19 cases and low-income status by neighbourhood in Toronto, Canada",
       fill = str_c("% of 18 to 64 year-olds in\n",
                    "low income families and\n",
                    "COVID-19 case rates"),
       caption = str_c("Created by: David Pham for STA303/1002, U of T\n", 
                       "Income data source: Census Profile 98-316-X2016001 via OpenData Toronto\n", 
                       "COVID data source: Ontario Ministry of Health, Integrated Public\n", 
                       "Health Information System and CORES\n", 
                       date_daily[1,1])) +
  theme(legend.position = 'right') +
  scale_fill_brewer(palette = 'Set1')
```